{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Flood Detection using Deep Learning (Finetuning MobileNet, KERAS)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import shutil\r\n",
    "import random\r\n",
    "import itertools\r\n",
    "%matplotlib inline\r\n",
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib as mpl\r\n",
    "from keras import backend\r\n",
    "from tensorflow import keras\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from keras.applications import imagenet_utils\r\n",
    "from tensorflow.keras.preprocessing import image\r\n",
    "from tensorflow.keras.layers import Dense, Activation\r\n",
    "from sklearn.metrics import precision_score, recall_score\r\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "from tensorflow.keras.applications.mobilenet import decode_predictions, preprocess_input"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "labels = ['Flooding', 'No Flooding']\r\n",
    "train_path = 'data/train'\r\n",
    "valid_path = 'data/valid'\r\n",
    "test_path = 'data/test'\r\n",
    "\r\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\r\n",
    "    directory=train_path, target_size=(224,224), batch_size=10)\r\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\r\n",
    "    directory=valid_path, target_size=(224,224), batch_size=10)\r\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\r\n",
    "    directory=test_path, target_size=(224,224), batch_size=10, shuffle=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 321 images belonging to 2 classes.\n",
      "Found 81 images belonging to 2 classes.\n",
      "Found 71 images belonging to 2 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "mobile = tf.keras.applications.mobilenet.MobileNet()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# last 5 layers of the mobilenet during finetuning as we want \r\n",
    "x = mobile.layers[-6].output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\r\n",
    "output = Dense(units=2, activation='softmax')(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\r\n",
    "model = Model(inputs=mobile.input, outputs=output)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for layer in model.layers[:-23]:\r\n",
    "    layer.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 3,230,914\n",
      "Trainable params: 1,865,730\n",
      "Non-trainable params: 1,365,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Ojas Karmarkar\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.fit(x=train_batches,\r\n",
    "          steps_per_epoch=len(train_batches),\r\n",
    "          validation_data=valid_batches,\r\n",
    "          validation_steps=len(valid_batches),\r\n",
    "          epochs=10,\r\n",
    "          verbose=2\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python39\\lib\\site-packages\\PIL\\Image.py:973: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "33/33 - 18s - loss: 0.2945 - accuracy: 0.8785 - val_loss: 0.1094 - val_accuracy: 0.9630\n",
      "Epoch 2/10\n",
      "33/33 - 12s - loss: 0.0830 - accuracy: 0.9564 - val_loss: 0.0706 - val_accuracy: 0.9753\n",
      "Epoch 3/10\n",
      "33/33 - 13s - loss: 0.0547 - accuracy: 0.9844 - val_loss: 0.0607 - val_accuracy: 0.9630\n",
      "Epoch 4/10\n",
      "33/33 - 12s - loss: 0.0459 - accuracy: 0.9875 - val_loss: 0.1223 - val_accuracy: 0.9506\n",
      "Epoch 5/10\n",
      "33/33 - 12s - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9383\n",
      "Epoch 6/10\n",
      "33/33 - 12s - loss: 0.0283 - accuracy: 0.9969 - val_loss: 0.0598 - val_accuracy: 0.9753\n",
      "Epoch 7/10\n",
      "33/33 - 12s - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9630\n",
      "Epoch 8/10\n",
      "33/33 - 12s - loss: 0.0405 - accuracy: 0.9813 - val_loss: 0.1926 - val_accuracy: 0.9383\n",
      "Epoch 9/10\n",
      "33/33 - 12s - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9259\n",
      "Epoch 10/10\n",
      "33/33 - 13s - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1280 - val_accuracy: 0.9383\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3415c03d0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Saving and loading our trained for future use\r\n",
    "\r\n",
    "model.save(\"model.h5\")\r\n",
    "# model.load_weights('fine_tuned_flood_detection_model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Make predictions and plot confusion matrix to look how well our model performed in classifying \r\n",
    "# flooding and no flooding images \r\n",
    "\r\n",
    "test_labels = test_batches.classes\r\n",
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)\r\n",
    "cm = confusion_matrix(y_true=test_labels, y_pred=predictions.argmax(axis=1))\r\n",
    "precision = precision_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\r\n",
    "f1_score = f1_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\r\n",
    "accuracy = accuracy_score(y_true=test_labels, y_pred=predictions.argmax(axis=1))\r\n",
    "def plot_confusion_matrix(cm, classes,\r\n",
    "                          normalize=False,\r\n",
    "                          title='Confusion matrix',\r\n",
    "                          cmap=plt.cm.Blues):\r\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
    "    plt.title(title)\r\n",
    "    plt.colorbar()\r\n",
    "    tick_marks = np.arange(len(classes))\r\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
    "    plt.yticks(tick_marks, classes)\r\n",
    "    thresh = cm.max() / 2.\r\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
    "        plt.text(j, i, cm[i, j],\r\n",
    "            horizontalalignment=\"center\",\r\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
    "\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.ylabel('True label')\r\n",
    "    plt.xlabel('Predicted label')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Pring precision, F1 score and accuracy of our model\r\n",
    "print('Precision: ', precision)\r\n",
    "print('F1 Score: ', f1_score)\r\n",
    "print('Accuracy: ', accuracy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision:  0.8235294117647058\n",
      "F1 Score:  0.9032258064516129\n",
      "Accuracy:  0.9154929577464789\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Confusion Matrix \r\n",
    "test_batches.class_indices\r\n",
    "cm_plot_labels = ['Flooding','No Flooding']\r\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate our finetuned model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Prepare image for mobilenet prediction\r\n",
    "\r\n",
    "def preprocess_image(file):\r\n",
    "    img_path = 'evaluate/'\r\n",
    "    img = image.load_img(img_path + file, target_size=(224, 224))\r\n",
    "    img_array = image.img_to_array(img)\r\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\r\n",
    "    return tf.keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Display image which we want to predict\r\n",
    "from IPython.display import Image\r\n",
    "Image(filename='evaluate/30.jpg', width=300,height=200) "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'evaluate/30.jpg'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\OJASKA~1\\AppData\\Local\\Temp/ipykernel_12296/893426017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Display image which we want to predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'evaluate/30.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[0;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[0;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1261\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1263\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'evaluate/30.jpg'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessed_image = preprocess_image('30.jpg')\r\n",
    "predictions = model.predict(preprocessed_image)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictions"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.9923564 , 0.00764361]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = np.argmax(predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels[result]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Flooding'"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE, This code was inspired and modified from the following source: \n",
    "https://deeplizard.com/.\n",
    "\n",
    "\n",
    "Flooding images were collected from paper named \"Detecting floodwater on roadways from image data with handcrafted features and deep transfer learning*\", available at \"https://arxiv.org/pdf/1909.00125.pdf\". \n",
    "\n",
    "Funfact: This model outperforms the model presented in the paper.\n",
    "\n",
    "Normal or No Flooding images were collected from google image search, there may be irrelevant images in this category\n",
    "because the images were downloaded using an automated script. \n",
    "\n",
    "The trained model performed quite impressively and got an accuracy score of over 98%."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import tensorflow as tf\r\n",
    "\r\n",
    "# model = tf.keras.models.load_model('model.h5')\r\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n",
    "# tflite_model = converter.convert()\r\n",
    "# open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\OJASKA~1\\AppData\\Local\\Temp\\tmp3_cajyaj\\assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12807944"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}